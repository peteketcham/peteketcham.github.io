[{"content":"\u003ch1 id=\"fun-progamming\"\u003eFun Progamming\u003c/h1\u003e\n\u003cp\u003eI\u0026rsquo;ve been doing some fun programming on the side off and on for years.  I can\u0026rsquo;t seem to get into things like LeetCode, and struggle to come up with ideas to do something new that will keep me engaged longer than a series of scripts, and came across \u003ca href=\"https://projecteuler.net/\"\u003eProject Euler\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eProject Euler problems are math heavy problems that you typically need to write code to solve.  They start out \u003ca href=\"https://projecteuler.net/problem=1\"\u003epretty simple\u003c/a\u003e, but quickly get complex and weird.  They\u0026rsquo;ll cover maths that need to be solved with set theory, or geometry, or statistics, or prime number theory, etc., etc., and are best solved by coming up with an appropriate algorithm for the task.  In general, any problem posted should be solvable with a few minutes of computer processing with the right algorithm.\u003c/p\u003e\n\u003ch2 id=\"problem-596\"\u003eProblem 596\u003c/h2\u003e\n\u003cp\u003eSo, I\u0026rsquo;ve solved 150+ problems at this point, and tend to skip around on different problems to solve.  One that looked really interesting, but ended up being devilishly hard for me to solve was \u003ca href=\"https://projecteuler.net/problem=596\"\u003eproblem 596\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe problem is as follows:\u003c/p\u003e\n\u003cp\u003eLet T(r) be the number of integer quadruplets x, y, z, t such that x^2 + y^2 + z^2 + t^2 â‰¤ r^2. In other words, T(r) is the number of lattice points in the four-dimensional hyperball of radius r.\u003c/p\u003e\n\u003cp\u003eYou are given that T(2) = 89, T(5) = 3121, T(100) = 493490641 and T(10^4) = 49348022079085897.\u003c/p\u003e\n\u003cp\u003eFind T(10^8) mod 1000000007.\u003c/p\u003e\n\u003ch2 id=\"first-attempt\"\u003eFirst attempt\u003c/h2\u003e\n\u003cp\u003eFor a first pass, I try and put together a really simple solution to validate the test case(s).  They almost never actually work to solve the problem since they scale poorly.  Here\u0026rsquo;s some simple code that covers every coordinate in the hypercube bounded by radius \u003ccode\u003ein_r\u003c/code\u003e.\u003c/p\u003e\n\u003cscript type=\"application/javascript\" src=\"https://gist.github.com/peteketcham/515aebdce33a29c16cd60fca29d90a11.js\"\u003e\u003c/script\u003e\n\n\u003cp\u003e\u003cstrong\u003eNOTE: This is just about unreadable in darkmode, toggle to light mode in the upper right of the page\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWhile great, this slows down \u003cstrong\u003every\u003c/strong\u003e quickly.  It runs in \u003ccode\u003eO(n^4)\u003c/code\u003e time, and wouldn\u0026rsquo;t be done until long after our sun is burned out and gone.\u003c/p\u003e\n\u003ch2 id=\"other-attempts\"\u003eOther attempts\u003c/h2\u003e\n\u003ch3 id=\"cube-inside-a-sphere\"\u003eCube inside a sphere\u003c/h3\u003e\n\u003cp\u003eSo if you take a circle of radius \u003ccode\u003er\u003c/code\u003e, and scribe a square inside of it, the sides of the square will be \u003ccode\u003e2*r / sqrt(2)\u003c/code\u003e and if you were following the axis up from the origin \u003ccode\u003e(0,0)\u003c/code\u003e, the last lattice point within the square would be \u003ccode\u003efloor(r / sqrt(2))\u003c/code\u003e.  That means that you can effectively count every point within that square and check the space between \u003ccode\u003er/sqrt(2)\u003c/code\u003e and \u003ccode\u003er\u003c/code\u003e instead.  For a hypersphere, that box works out to \u003ccode\u003er / 2\u003c/code\u003e of lattice points that are immediately counted.\u003c/p\u003e\n\u003cp\u003eAdditionally, there are boxed spaces you can immediately rule out as not having any \u0026ndash; that is, if \u003ccode\u003eabs(x)\u003c/code\u003e, \u003ccode\u003eabs(y)\u003c/code\u003e, \u003ccode\u003eabs(z)\u003c/code\u003e, and \u003ccode\u003eabs(t)\u003c/code\u003e are all greater than \u003ccode\u003er // 2\u003c/code\u003e (Quick Python note: \u003ccode\u003e//\u003c/code\u003e returns \u003ccode\u003efloor(x / y)\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eWhile this is great, it\u0026rsquo;s only a fractional change.  It rules out just over half of the problem space, but it\u0026rsquo;s still a problem set that grows exponentially with the radius, and not a workable solution.\u003c/p\u003e\n\u003cp\u003eWe\u0026rsquo;re at about 7/16 of the orignal problem size with this change.\u003c/p\u003e\n\u003ch3 id=\"setting-scope\"\u003eSetting scope\u003c/h3\u003e\n\u003cp\u003eAfter reducing the space by cutting out the center and the corners, we can try and reduce it more by handling translation across the different dimensions.  For example in a circle, if \u003ccode\u003e(x, y)\u003c/code\u003e is within the cirlce, so is \u003ccode\u003e(x, -y)\u003c/code\u003e, \u003ccode\u003e(-x, y)\u003c/code\u003e, and \u003ccode\u003e(-x, -y)\u003c/code\u003e.  If you take care to catch situations where points lie on an axis or are the same value so they aren\u0026rsquo;t double counted (e.g., \u003ccode\u003e(1, 2, 0, 0)\u003c/code\u003e or \u003ccode\u003e(1, 2, 3, 3)\u003c/code\u003e), you can take your match and multiply it by 16 to catch all the different quadrants the coordinates end up in.\u003c/p\u003e\n\u003cp\u003eSimilarly, you can reduce by the permutations of the coordinates.  If \u003ccode\u003e(1, 2, 3, 3)\u003c/code\u003e is in the circle, so is \u003ccode\u003e(1, 3, 2, 3)\u003c/code\u003e and \u003ccode\u003e(1, 3, 3, 2)\u003c/code\u003e, and so on.  If the numbers are all unique, there are 24 different permutations.\u003c/p\u003e\n\u003cp\u003eBetween these and the cube within a sphere above, we\u0026rsquo;re down to a problem space of \u003ccode\u003e(1 - 9/16) * (1 / 16) * (1 / 24)\u003c/code\u003e, or about \u003ccode\u003e0.11%\u003c/code\u003e of the original area.\u003c/p\u003e\n\u003cp\u003eStill \u003ccode\u003eO(n^4)\u003c/code\u003e, still more work to do\u0026hellip;\u003c/p\u003e\n\u003ch3 id=\"multithreading\"\u003eMultithreading\u003c/h3\u003e\n\u003cp\u003eOk, now lets say we have a fancy computer with a whole mess of cores that are just sitting there unused while we wait for the heat death of the universe!  Let\u0026rsquo;s put them all to work!\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom multiprocessing import Pool, cpu_count\nfrom functools import partial\n\n\ndef calc_inner_4cube(in_r):\n    return in_r**4  # (2*in_r//2)**4\n\n\ndef x_loop(x_axis, in_r):\n    ring = in_r**2\n    result = 0\n    temp_ring_y = int((ring - x_axis**2)**.5)\n    for y_axis in range(x_axis, temp_ring_y + 1):\n        temp_ring_z = int((temp_ring_y - y_axis**2)**.5)\n        for z_axis in range(y_axis, temp_ring_z + 1):\n            temp_ring_t = int((temp_ring_z - z_axis**2)**.5)\n            for t_axis in range(z_axis, temp_ring_t + 1):\n                if ring \u0026gt;= x_axis**2 + y_axis**2 + z_axis**2 + t_axis**2:\n                    result += 1\n    return result\n\n\ndef mp_brute_calc(in_r):\n    \u0026#34;\u0026#34;\u0026#34;iterate through hypercube of radius r\u0026#34;\u0026#34;\u0026#34;\n    ring = in_r**2\n    result = calc_inner_4cube(in_r)\n    worker_x = partial(x_loop, in_r=in_r)\n    with Pool(cpu_count() - 1) as poolio:\n        result += sum(poolio.map(worker_x, range(in_r // 2, in_r + 1)))\n    return result\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow as long as we have enough system memory to hold a 10^8 Python list in memory, we\u0026rsquo;re good to go.  Oh wait, still \u003ccode\u003eO(n^4)\u003c/code\u003e\u0026hellip;\u003c/p\u003e\n\u003ch2 id=\"final-point\"\u003eFinal point\u003c/h2\u003e\n\u003cp\u003eAll of this work refining, and we\u0026rsquo;ve managed to speed up from the brute force by over 99.95%!  \u0026hellip;and it\u0026rsquo;s still FAR too slow.  Time for a new approach.  How can I reduce the number of dimensions we\u0026rsquo;re checking across?  Is this a problem that I can find an answer to for spheres?  Or circles?  \u003ca href=\"https://mathworld.wolfram.com/GausssCircleProblem.html\"\u003eGauss\u0026rsquo; Circle Problem\u003c/a\u003e!\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eN(r) = 1 + 4 * r + 4 + sum((int(sqrt(r\\*\\*2 - i\\*\\*2)) for i in range(1, r+1)))\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSo we can\u0026rsquo;t use this with the shortcuts from the second bit of code, but we can take the first one, adjust the ranges and can combine z and t axes into a single loop:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efor x_axis in range(-in_r, in_r+1):\n    temp_ring_y = int((in_r**2 - x_axis**2)**.5)\n    for y_axis in range(-1 * temp_ring_y, temp_ring_y + 1):\n        r = int((temp_ring_y - y_axis**2)**.5)\n        result += 1 + 4 * r + 4 + sum((int(sqrt(r\\*\\*2 - i\\*\\*2)) for i in range(1, r+1)))\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNot bad, down to \u003ccode\u003eO(n^3)\u003c/code\u003e!  Project Euler solutions aren\u0026rsquo;t really supposed to be shared for anything after problem 100, so I\u0026rsquo;ll leave it here.\u003c/p\u003e\n","description":"","image":null,"permalink":"https://www.peteketcham.com/blog/project-euler/","title":"Project Euler"},{"content":"\u003ch2 id=\"datacenter-migration\"\u003eDatacenter Migration\u003c/h2\u003e\n\u003cp\u003eAt a previous employer, their growth into new businesses had\ntraditionally been through acquisition of other companies. My team was responsible\nfor supporting the production and QA environments for applications servicing the\naccounting and tax markets. Typically, our role would involve onboarding,\nreleases, building of new servers and environments,\ndecommissioning of old servers, applications, and environments, setting\nup of monitoring and the overall lifecycle of the application. We would\nserve as a liaison between the development and DevOps teams and the\ndatacenter services teams (e.g., OS management, database, networking,\netc.).\u003c/p\u003e\n\u003ch2 id=\"the-project\"\u003eThe Project\u003c/h2\u003e\n\u003cp\u003eOne of the applications we were tasked with onboarding was a product suite I\u0026rsquo;m going to refer to as OTP. This was a new\nproduct category for the company and industry, due to\nnew market regulations a few years earlier. The acquiured business was about 4\nyears old at this point and they were running out of a managed services\n3rd party datacenter. I was tasked with the planning and orchestration\nof the move into a company owned and managed datacenter.\u003c/p\u003e\n\u003cp\u003eThis business was a suite of several different products:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOTP \u0026ndash; \u0026ldquo;One Tax Product\u0026rdquo;, the flagship application.\u003c/li\u003e\n\u003cli\u003eMini-OTP \u0026ndash; Barebones version of OTP intended for data entry for\nlimited users.\u003c/li\u003e\n\u003cli\u003eUTP \u0026ndash; \u0026ldquo;Uther[sp.] Tax Product\u0026rdquo;, began as a rewrite of OTP as a\nweb-based application, but was transitioned into a wholly new\nproduct offering halfway through development.\u003c/li\u003e\n\u003cli\u003eOXTP \u0026ndash; \u0026ldquo;Other Cross Tax Product\u0026rdquo;, custom app for a single customer\nthat became a wholly new product offering.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDue to some contractual obligations, these apps were running multiple\ndifferent versions of each product in production for different subsets\nof customers. For example, OTP and Mini-OTP were running around two\ndozen different versions of code across 4 years of releases, and UTP and\nOXTP were running 4-6 versions each. These apps were not architected in similar\nways\u0026mdash;OTP and OXTP were Windows desktop applications that were running\nin a VDI farm (one with an Oracle DB backend, and the other with\nMSSQL, and OTP had additional functionality on webservers accessed\nthrough a web frame within the application), Mini-OTP was a minimal\nsubset of OTP functionality running in a Tomcat instance across Linux\nservers (and sharing the OTP database), UTP was a Tomcat application\nthat had custom Java daemon helper processes for managing data (e.g.,\nETL) into a MongoDB database for reports in addition to an Oracle DB for\ncustomer data.\u003c/p\u003e\n\u003ch2 id=\"the-setup\"\u003eThe Setup\u003c/h2\u003e\n\u003cp\u003eWhen I was brought on to help drive this migration, most of the\ninstitutional knowledge for the applications had already left the\ncompany\u0026mdash;the entire DevOps team had quit, as well as several key\ndevelopers. Several groups of leadership from the datacenter operations\nbusiness unit had been out to their remote office in New Jersey to try\nand build a relationship but all their interactions were still very\nacrimonious. There were regularly heated arguments over any and every\nattempt to find common ground and to plan out what their application\nmigration would look like, and no progress had been made yet. With that\nhistory in mind, I was flown out to their office to build a relationship\nwith the former call center staff that had been appointed to take over\nfor the DevOps team, integrate them into my application support team,\nand to start building out knowledge of the applications and operations\nto make any sort of headway into supporting their business.\u003c/p\u003e\n\u003cp\u003eOn the first day I was in their office, I met with the teams and started\nto sit down and work through what information and runbooks were\navailable and to start to get a general lay of the land. That afternoon,\nwhile working through the application\u0026rsquo;s architectures, we were\ninterrupted by another member of the call center staff that the UTP\napplication had gone down and they were unable to get it back up and\nrunning. I took the opportunity to take what they\u0026rsquo;d done so far, what\nthe error messages were, and start walking through the architecture with\nthem to track down the problem.\u003c/p\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/migration/utp-arch.svg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003cp\u003eWalking through it step by step, they guided me to quickly draw up the\napplications functions on a whiteboard and how work flowed through the\nsystem. We quickly found that:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThey had no errors on the web tier of the application\u003c/li\u003e\n\u003cli\u003eThe ETL processes were throwing error messages across all parts of\nthe process and all versions\n\u003cul\u003e\n\u003cli\u003eThe errors persisted through a service restart\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMongoDB was showing no errors\u003c/li\u003e\n\u003cli\u003eThe Oracle DB was showing no errors\n\u003cul\u003e\n\u003cli\u003eThey were able to verify that transactions involving the DB were\ncompleting successfully.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAs we mapped it out how these pieces fit together, I was able to point\nout to the team that while MongoDB was not giving any errors, that was\nthe only common piece across all the error messages being presented and\nasked what steps can we take to verify its health? It came out that\nthere was no knowledge on what it did or why it was there. It was\nimplemented by a now-former developer as part of the ETL reporting\nprocess. I asked to check out the server directly and quickly discovered\nthat the filesystem had filled up\u0026mdash;reports were being generated, loaded\ninto MongoDB, passed on to the next step, but never cleaned out of the\nqueue. With no one having any knowledge of how to manage MongoDB, I\nquickly found a stop gap solution to clear out the database\u0026mdash;clear out\nall documents older than today\u0026rsquo;s date. After verifying that data-loss in\nthis piece was acceptable since the documents were only used in a\ntemporary fashion, I ran the commands to clear up space and we were able\nto get the application up and running again. After a few hours\nmonitoring the disk space on the server, we were able to verify that the\nrate growth meant it would be months before the issue would recur and\nwere able to put bug fix request in the developer\u0026rsquo;s queue to remedy.\u003c/p\u003e\n\u003cp\u003eThis ended up being the spark to build a positive relationship with the\nbusiness. They had been so slammed with day-to-day issues like this and\nweren\u0026rsquo;t sharing that these were happening that it hadn\u0026rsquo;t been\ncommunicated clearly that I (and my team) were there to help them as\ntheir partners to help solve these problems with the applications and\nultimately make the business more stable and reliable. I spent the rest\nof the next two weeks in the office with them going over all the\napplications and their many parts in as much detail as we could fit in\nand was able to return home with far more information to work with than\nany of us had before.\u003c/p\u003e\n\u003ch2 id=\"working-the-project\"\u003eWorking the Project\u003c/h2\u003e\n\u003cp\u003eReturning home from my site visit, I was given a new direction and\ngoal\u0026mdash;over the next 12 months, I would build out and test all the\napplications in the company-owned datacenter and plan for a migration at\nthe end of that window. Additionally, the new DevOps team from the\nbusiness would be rolled into my existing team. I set our first\nmilestone\u0026mdash;get OTP 9.20 up and running successfully (the dozens of\nversions running in production varied between 5.0.x and 9.20). Over the\nnext 9 months, I met with the developers, the new DevOps engineers, QA\ntesters, and the help desk staff daily as we worked through\ninstallation, configuration, and behaviors of the application. We\u0026rsquo;d meet\nmultiple times a week with project managers and leadership from the\nbusiness as well as the datacenter operations teams to go over progress,\nblocking issues, and the ongoing business of the applications (as\nregular issues and releases continued to progress in parallel to the\nmigration). At the end of the 9 months, we reached a point where we\u0026rsquo;d\nmanaged to get most functionality working for that single version of\nOTP, but it was becoming clear that we weren\u0026rsquo;t going to finish within 12\nmonths, as the remaining applications and sub-versions were far from\nbeing up and running. I brought 4 contractors into the project at this\npoint to help with the workload, and the migration was pushed out for\nanother 9 months. I also obtained:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA tech writer to help document runbooks, architectures, processes,\netc.\u003c/li\u003e\n\u003cli\u003eA Linux systems administrator to help with the setup,\nadministration, and automation for UTP and Mini-OTP\u003c/li\u003e\n\u003cli\u003eA Virtualization/Windows administrator to help with setup,\nadministration, and automation for the desktop app portion of OTP\u003c/li\u003e\n\u003cli\u003eA Windows administrator/generalist to help with the IIS and \u0026lsquo;other\u0026rsquo;\nportions of the applications\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAdditionally, both the business and the datacenter operations groups\ndedicated a project manager to help with the orchestration\u0026mdash;what are\nour blocking issues, who else needs to be brought in, what leverage can\nbe applied to make certain tasks go faster, etc.\u003c/p\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/migration/otp-arch.svg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003cp\u003eWith more people involved in the migration, my role transitioned into a\nproject lead\u0026mdash;I would find and assign tasks, assist the team with their\ntasks, and dive in on tasks that were particularly complex and/or of\nhigh priority. The large number of versions running brought up a lot of\nissues with versioning of their dependencies\u0026mdash;ODBC driver versions that\nwould work for some versions would work for others, and the installers\nwould overwrite other versions if they weren\u0026rsquo;t applied in a specific\norder. QA testing would pass on versions, and then fail in previously\nundocumented ways on other servers. As part of the transition, we were\nalso migrating up two versions of Windows Server, and had similar issues\nwith .NET and it\u0026rsquo;s required assemblies that had not been documented in\nany of the application information. Every week brought new challenges to\nsolve for everyone involved.\u003c/p\u003e\n\u003cp\u003eAs the business was an acquired startup, the applications were not\ndesigned with scalability in mind. There were multiple issues around how\nthis played out, but a prominent issue was that about half of the\ncustomers for Mini-OTP and UTP were single tenant. They would have\ndozens of customers each having their own custom configured web\napplication (packaged into a WAR file) running in Tomcat for the\napplication, with hardcoded unique connection strings and other\ncustomizations within the package. There was no artifact or\nconfiguration management at the time, so the Linux admin contractor that\nwas brought on and I worked on creating a script to manage updating the\nhundreds of WAR files for the migration. The script would traverse the\nappropriate paths within the Tomcat installation, and with each file,\nversion it, find the appropriate files within the WAR and strings within\nthe file to update, repackage the WAR, and then force a redeploy in\nTomcat.\u003c/p\u003e\n\u003cp\u003eWork progressed at a steady pace for the next 9 months, with me and my\nteam deploying functions, sending them to QA to test, troubleshoot, and\nworked into a regular rhythm where we would find an issue, solve an\nissue, and then a new issue would be found, and the cycle would repeat.\nWhile the Linux contractor was working through issues with Mini-OTP and\nUTP, the other two sysadmin contractors were working through OTP and\nOXTP, with the tech writer checking in to compile their notes and\nlessons into a consistent style and voice.\u003c/p\u003e\n\u003cp\u003eThrough regular conversations with the business, my team and I targeted\nspecific versions of code that were causing the most issues, and the\nbusiness worked with the customers to get them upgraded as much as\npossible and were able to eliminate about half a dozen versions of code\n(v7.x specifically had irreconcilable issues we were never able to pin\ndown) by migrating them to newer application versions.\u003c/p\u003e\n\u003cp\u003eDuring this time, we also started planning out the migration date\u0026mdash;what\ndays worked with known blackouts, contacting key customers, steps and\norder for the migration, what parties had steps and what they would\ninvolve, and what criteria constituted a successful failover vs forcing\na rollback.\u003c/p\u003e\n\u003cp\u003eFor the migration, several leaders from the business flew from their\noffice in NJ to MN, and representatives from all the parties involved in\nthe cutover setup in a war room at the office. We started around 9pm CT\nin the evening with shutdowns and putting up offline notifications, and\nbegan with application and database cutovers, which would take hours to\ncomplete. Around 2am CT, key functions were up and running again, and\npieces were handed of for QA testing as they came online. We concluded\nthe migration at 7am CT when all key functionalities had been tested and\nverified as working, and while there were issues remaining, they were\nall minor enough that they could be fixed in the coming weeks.\u003c/p\u003e\n\u003ch2 id=\"retrospective\"\u003eRetrospective\u003c/h2\u003e\n\u003cp\u003eThe impact of completing this project was a cost savings of over $1\nmillion per year in hosting costs and significantly improved\nuptime\u0026mdash;from more than 24 hours of impact from infrastructure\nmaintenance and issues to less than an hour per year (~99.5% to 99.99%\nuptime). The automation and tooling developed in the migration made\nfuture releases go more smoothly, monitoring tools available in the new\ndatacenter gave better visibility into application health, and the\nscrutiny from poring over the applications in such detail allowed us to\nfind and remedy multiple security vulnerabilities. The improved\nrelationship between the business and datacenter operations helped each\nbetter anticipate the other\u0026rsquo;s needs and opened the door for additional\nintegrations between OTP and other company products.\u003c/p\u003e\n\u003cp\u003eI learned a lot about managing without influence\u0026mdash;working with teams\nand individuals that have no organizational reason to help, working with\nindividuals that actively don\u0026rsquo;t want to help, and how useful it is to\napproach these interactions by framing it as \u0026lsquo;what\u0026rsquo;s in it for them\u0026rsquo;.\nThis really made me examine what it means to be a leader vs a manager,\nand the example I wanted to set as a leader. The business learned to\nbetter collaborate with outside teams and have more open and honest\ncommunication across organizational boundaries, and the datacenter\noperations team started approaching the groups as more of a\ncollaboration and not simply in a top-down manner.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://www.peteketcham.com/blog/migration/","title":"Rehosting"},{"content":"\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/harvest-dinner/plated.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003cp\u003eI was asked at the end of September if I would be willing to do the harvest dinner this past November at my church, and it ended up being quite the event\u0026ndash; I planned the menu, picked up the ingredients, and cooked (with lots of wonderful help) a delicious meal for 100 people.  It was fun, and hard, and complex, and wanted to share the recipes and some background of the different things that were made.\u003c/p\u003e\n\u003ch2 id=\"squash-soup\"\u003eSquash Soup\u003c/h2\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/harvest-dinner/squash.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003cp\u003e\u003ca href=\"https://web.archive.org/web/20180310140709/http://vegenistaskitchen.com/blue-hubbard-squash-bisque/\"\u003eSquash bisque soup!\u003c/a\u003e This was one of several giant blue hubbard squash that were grown out at the in-laws this past summer.  I couldn\u0026rsquo;t think of how to eat it all before it went bad, and what better way than to serve a crowd?  I didn\u0026rsquo;t follow the recipe exactly\u0026ndash; I subbed out cashew cream for heavy cream, and I\u0026rsquo;m pretty sure I still ended up light on the squash and heavy on the broth, and accidentally added the sage and thyme to the roast carrots instead of the soup, but it came out delicious.\u003c/p\u003e\n\u003ch2 id=\"cornbread\"\u003eCornbread\u003c/h2\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/harvest-dinner/cornbread.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003cp\u003eThis is my go-to recipe right now; I can\u0026rsquo;t remember the multiple I used to fill a pan this size\u0026ndash; 12x maybe?  You can find the recipe \u003ca href=\"https://mygluten-freekitchen.com/best-sweet-cornbread-gluten-free/\"\u003ehere\u003c/a\u003e.  What\u0026rsquo;s worked well for me has been \u003ca href=\"https://www.bobsredmill.com/coarse-grind-cornmeal.html\"\u003eBob\u0026rsquo;s Red Mill coarse grind cornmeal\u003c/a\u003e and \u003ca href=\"https://www.bobsredmill.com/gluten-free-1-to-1-baking-flour.html\"\u003eBob\u0026rsquo;s Red Mill 1:1 GF baking flour\u003c/a\u003e.  The nice thing about this recipe is doubling the recipe works out to 1 bag of cornmeal, 1 bag of the flour, 1lb. butter, and 1 qt buttermilk.\u003c/p\u003e\n\u003ch2 id=\"cranberry-relish\"\u003eCranberry Relish\u003c/h2\u003e\n\u003cp\u003eOld friend\u0026rsquo;s family recipe that\u0026rsquo;s approximately the same as what you\u0026rsquo;ll find in a search online\u0026ndash;\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e1 bag cranberries\u003c/li\u003e\n\u003cli\u003e1 orange\u003c/li\u003e\n\u003cli\u003e1 apple\u003c/li\u003e\n\u003cli\u003e1 cup sugar\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBlend, puree, or grind the apple, orange, and cranberries, mix with sugar and let set overnight in the fridge for the flavors to meld.\u003c/p\u003e\n\u003ch2 id=\"roast-carrots-and-potatoes\"\u003eRoast Carrots and Potatoes\u003c/h2\u003e\n\u003cp\u003eFor the carrots, I mostly eyeballed the \u003ca href=\"https://www.seriouseats.com/roasted-carrots-harissa-creme-fraiche-food-lab-recipe\"\u003erecipe\u003c/a\u003e.\nNo creme fraiche, no harissa, I added sage and thyme, and didn\u0026rsquo;t need to toss during roast.\nAdding some maple syrup (or better yet, maple vinegar) to the parboil for the carrots would be tasty, maybe next time.\u003c/p\u003e\n\u003cp\u003eThe \u003ca href=\"https://www.seriouseats.com/the-best-roast-potatoes-ever-recipe\"\u003eroast potatoes\u003c/a\u003e are always delicious, but\nthe serving suggestion is way too small\u0026ndash; as posted it serves 4; it goes fast and never seems to serve that many.\nI\u0026rsquo;ve only done it with gold potatoes and haven\u0026rsquo;t tried russets and\nI\u0026rsquo;ve always used olive oil to keep it vegetarian, but the duck fat suggestion sounds \u003cem\u003ereally\u003c/em\u003e good, if you have the opportunity.\nSave an extra bowl to clean and add the potatoes back to the stock pot and shake with the lid on.\nIf you aren\u0026rsquo;t a fan of garlic, you don\u0026rsquo;t miss much if you skip it.\nAdding the rosemary and garlic back at the end doesn\u0026rsquo;t matter much, especially when it\u0026rsquo;s \u003cem\u003eSO\u003c/em\u003e easy to burn them when you cook them in the oil. it won\u0026rsquo;t make the oil taste off if they end up a little burnt, but adding the burnt rosemary and garlic at the end would\u0026hellip;\u003c/p\u003e\n\u003ch2 id=\"brisket\"\u003eBrisket\u003c/h2\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/harvest-dinner/brisket.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003cp\u003eSo many briskets.  My father-in-law smoked 9 briskets on the smoker\u0026ndash; had to rig them up to stand vertically to fit them all in.  The usual prep is to coat the brisket in yellow mustard, rub down with a spice rub (varies, but Meat Church has been the go-to for a while), wrap in plastic and let sit for several hours.  After that, it goes in the smoker for several more hours, then a wrap in foil, continue to cook until it gets to temperature, then a rest in a cooler for several hours before serving.  I wish I had a good picture of these, they came out \u003cem\u003ebeautifully\u003c/em\u003e.\u003c/p\u003e\n\u003ch2 id=\"creme-caramel\"\u003eCreme Caramel\u003c/h2\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/harvest-dinner/creme-caramel-plated.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003cp\u003eFrom \u003ca href=\"https://www.americastestkitchen.com/recipes/1016-classic-creme-caramel\"\u003eAmerica\u0026rsquo;s Test Kitchen\u003c/a\u003e cookbook. It\u0026rsquo;s behind a paywall but is in their big red cookbook if you\u0026rsquo;ve got it.\u003c/p\u003e\n\u003cp\u003eIt\u0026rsquo;s good!  It\u0026rsquo;s easy!  It\u0026rsquo;s a huge pain to clean at the end!  That said, the caramel can be a bit tricky\u0026ndash; it quickly goes from boiling, to straw-colored, to burnt, so keep a close eye on it with a candy thermometer and move quickly when it\u0026rsquo;s done.\u003c/p\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/harvest-dinner/creme-caramel.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003ch2 id=\"wrap-up\"\u003eWrap up\u003c/h2\u003e\n\u003cp\u003eThe dinner was super successful.  I made far more food than we had for guests (in proper midwest fashion), but we made a bunch of meals for takeaway and froze and sold the rest of the leftovers separately.  I\u0026rsquo;m happy to say I keep hearing from people who tell me how great all the food was.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://www.peteketcham.com/blog/harvest-dinner/","title":"Harvest Dinner"},{"content":"\u003ch1 id=\"quick-3d-model-for-elevating-a-wide-mouth-pint-jar\"\u003eQuick 3D model for elevating a wide mouth pint jar\u003c/h1\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/quick-jar-lift/finished.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n\u003cp\u003eWe\u0026rsquo;ve hit full winter blues at home, and have decided to start some plants really early.  They might end up being microgreens, they might not make it, who knows, but first the seeds have to germinate.  As part of that, they\u0026rsquo;re wet a few times a day and are left to figure it out in the jar.  So they don\u0026rsquo;t end up sitting in water, the jar needs to be upside down, and lifted from the countertop.  I went into \u003ca href=\"https://www.tinkercad.com\"\u003eTinkercad\u003c/a\u003e and created this model in about 15 minutes:\u003c/p\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/quick-jar-lift/model.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n","description":null,"image":null,"permalink":"https://www.peteketcham.com/blog/quick_jar_lift/","title":"Quick Jar Lift"},{"content":"\u003cp\u003eHello World!\u003c/p\u003e\n\n\n\n\n\u003cimg alt=\"\" title=\"\" data-src=\"https://res.cloudinary.com/dacpz9qg0/w_auto,c_scale,f_auto,q_auto,dpr_auto/images/cicada.jpg\" class=\"cld-responsive\" style=\"padding-bottom: 16px; display: block; margin: auto; max-width:80%\"\u003e\n\n","description":null,"image":null,"permalink":"https://www.peteketcham.com/blog/my-first-post/","title":"My First Post"},{"content":"","description":null,"image":null,"permalink":"https://www.peteketcham.com/search/","title":"Search"}]